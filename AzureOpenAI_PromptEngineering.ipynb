{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "d1902c4a-2f16-4886-8ca7-bee9ef32837c",
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "# Introduction\n",
        "\n",
        "Prompt engineering is a concept in Natural Language Processing (NLP) that involves embedding descriptions of tasks in input to prompt an AI model to output the desired results.  A prompt typically includes the problem description, instructions on how to solve the problem,Â and examples of correct problem and solution pairs.\n",
        "\n",
        "This notebook provides a few samples of prompts used to accomplish tasks like, text generation, summarization, and classification using the Azure OpenAI Service."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3630c235-f891-4874-bd0a-5277d4d6aa82",
      "metadata": {},
      "source": [
        "## Setup\n",
        "\n",
        "Configuration for using an Azure OpenAI endpoint.  You must first have setup you service and deployed a gpt-35-turbo model.  For instructions to set this up, please see [Resource creation & model deployment](https://learn.microsoft.com/en-us/azure/cognitive-services/openai/how-to/create-resource?pivots=web-portal) and more information about [GPT-35-Turbo & GPT-4 models] (https://learn.microsoft.com/en-us/azure/cognitive-services/openai/how-to/chatgpt?pivots=programming-language-chat-completions).\n",
        "\n",
        "These prompts should work with other model families as well, but has only been tested with that type, and you may see different results to the prompts shown."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "d16a17a0-faaa-46dd-b430-761ee293398f",
      "metadata": {
        "gather": {
          "logged": 1689181077435
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [],
      "source": [
        "#!pip install openai"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "1b87a622-91be-4f3c-95cf-da4214a33d4f",
      "metadata": {
        "gather": {
          "logged": 1689181079269
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [],
      "source": [
        "import openai\n",
        "import os\n",
        "import json"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "985c4de4-4ba8-4deb-915f-7e2e45333de1",
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "### Parameter Configuration\n",
        "Edit (or create) the config.json file to associate with this notebook containing the information for the Azure OpenAI endpoint you created.\n",
        "\n",
        "\n",
        "```\n",
        "{\n",
        "    \"OPENAI_API_BASE\":\"https://<Your Azure Resource Name>.openai.azure.com\",\n",
        "    \"OPENAI_API_KEY\":\"<OpenAI API Key>\",\n",
        "    \"OPENAI_API_VERSION\":\"<OpenAI API Version>\",\n",
        "    \"GPT_MODEL\":\"<GPT Model Deployment Name>\"\n",
        "}\n",
        "```\n",
        "\n",
        "**NOTES:** \n",
        "* Access the OPENAI_API_KEY value from the Azure Portal. Go to https://portal.azure.com, find your resource and then under \"Resource Management\" -> \"Keys and Endpoints\" look for one of the \"Keys\" values.\n",
        "\n",
        "* This notebook uses the ChatCompletion method of the [OpenAI Python Library](https://github.com/openai/openai-python#chat-completions) -  the versions supported for Azure OpenAI are listed in [Chat completions API Reference](https://learn.microsoft.com/en-us/azure/cognitive-services/openai/reference#chat-completions).  The \"2023-05-15\" version was used for this notebook.\n",
        "\n",
        "The next step loads the configurations from config.json file to setup openai_api_base, openai_api_key, openai_api_version, type, and model deployment within the notebook."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "ed6efe3b-e830-4397-9884-b989e3eec72c",
      "metadata": {
        "gather": {
          "logged": 1689181082215
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [],
      "source": [
        "# Load config values\n",
        "with open(r'config.json') as config_file:\n",
        "    config_details = json.load(config_file)\n",
        "\n",
        "# The base URL for your Azure OpenAI resource. e.g. \"https://<your resource name>.openai.azure.com\"\n",
        "openai_api_base = config_details['OPENAI_API_BASE']\n",
        "\n",
        "# The API key for your Azure OpenAI resource.\n",
        "openai_api_key = config_details[\"OPENAI_API_KEY\"]\n",
        "\n",
        "# See Notes above for version options (format is YYYY-MM-DD)\n",
        "openai_api_version = config_details['OPENAI_API_VERSION']\n",
        "\n",
        "# The model deployment name from OpenAI service.\n",
        "deployment_name = config_details['GPT_MODEL']\n",
        "\n",
        "openai.api_base = openai_api_base\n",
        "openai.api_key = openai_api_key\n",
        "openai.api_version = openai_api_version\n",
        "openai.api_type = \"azure\""
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d27d1e90-97e3-46d1-a58e-fbd90301fd98",
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "### AOAI API Call\n",
        "\n",
        "This function is used throughout the notebook to manage requests to the Azure OpenAI service."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "0b4d4411-d1f6-45fe-a106-edf3b02903ef",
      "metadata": {
        "gather": {
          "logged": 1689181089231
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [],
      "source": [
        "# manages call to API to get a ChatCompletion for a text prompt/message.\n",
        "def aoai_completion(user_request=None, messages=None, model=deployment_name, temperature=0):\n",
        "\n",
        "    if messages == None:\n",
        "        messages = [{\"role\": \"user\", \"content\": user_request}]\n",
        "\n",
        "    response = openai.ChatCompletion.create(\n",
        "        engine=model,\n",
        "        messages=messages,\n",
        "        temperature=temperature, \n",
        "    )\n",
        "\n",
        "    return response, response.choices[0].message[\"content\"]"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f7f08070-c2cf-4b3e-99cd-92a65dac6450",
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "## Simple Prompt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f84d1dda-e69c-4213-9113-f566a7e5fa08",
      "metadata": {
        "gather": {
          "logged": 1689181100422
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Customer: Hello, how are you?\n",
            "\n",
            "Assistant Response: As an AI language model, I don't have feelings, but I'm functioning well. How can I assist you today?\n",
            "\n",
            "Prompt tokens: 14\n",
            "Completion tokens: 25\n",
            "Total tokens: 39\n"
          ]
        }
      ],
      "source": [
        "# Example prompt to check connectivity\n",
        "prompt = \"Hello, how are you?\"\n",
        "\n",
        "aoai_response, completion = aoai_completion(prompt)\n",
        "print(f\"Customer: {prompt}\")\n",
        "print(f\"\\nAssistant Response: {completion}\")\n",
        "print(f'\\nPrompt tokens: {aoai_response[\"usage\"][\"prompt_tokens\"]}')\n",
        "print(f'Completion tokens: {aoai_response[\"usage\"][\"completion_tokens\"]}')\n",
        "print(f'Total tokens: {aoai_response[\"usage\"][\"total_tokens\"]}')"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f6825599",
      "metadata": {},
      "source": [
        "## Text Classification "
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7195eec0",
      "metadata": {},
      "source": [
        "### Named Entity Recognition (Zero-Shot)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b6020628",
      "metadata": {},
      "outputs": [],
      "source": [
        "address = \"\"\"\n",
        "Dear Kelly,\n",
        "It was great to talk to you at the seminar. I thought Jane's talk was quite good.\n",
        "Thank you for the book. Here's my address 2111 Ash Lane, Crestview CA 92002\n",
        "Best,\n",
        "Maya\n",
        "\"\"\"\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f5a4a2f0",
      "metadata": {},
      "outputs": [],
      "source": [
        "prompt = f\"\"\"\n",
        "Extract the name and mailing address from this email:\n",
        "\n",
        "Mailing Address: ```{address}```\n",
        "\n",
        "\"\"\"\n",
        "aoai_response, completion = aoai_completion(prompt)\n",
        "print(f\"Customer: {prompt}\")\n",
        "print(f\"\\nAssistant Response: {completion}\")\n",
        "print(f'\\nPrompt tokens: {aoai_response[\"usage\"][\"prompt_tokens\"]}')\n",
        "print(f'Completion tokens: {aoai_response[\"usage\"][\"completion_tokens\"]}')\n",
        "print(f'Total tokens: {aoai_response[\"usage\"][\"total_tokens\"]}')"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5755f072-50ad-4c60-a687-71e4d321948d",
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "## Summarization"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "10c91f69-ce04-49a9-ac5b-4769d20c54bb",
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "### Semantic Summarization\n",
        "\n",
        "Generates new text using natural language generation techniques that represents the most relevant/important information."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "9bc97af5-7fc8-47ed-a420-b8446449c6e4",
      "metadata": {
        "gather": {
          "logged": 1689181135874
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [],
      "source": [
        "recipe = \"\"\"\n",
        "Making sourdough bread is a bit different from making regular bread because it requires a sourdough starter. \n",
        "To make the starter, you'll need flour and water. Mix equal parts of flour and water in a jar and leave it on your \n",
        "counter. After a few days, the mixture will start to bubble and ferment, which is when the sourdough starter is ready \n",
        "to use.\\n\\nOnce you have the starter, you'll need to mix it with more flour and water to make the bread dough. \n",
        "In a mixing bowl, add the flour, salt, and a portion of the sourdough starter. Slowly mix in water until the dough \n",
        "comes together and is slightly sticky.\\n\\nKnead the dough for about 10 minutes on a floured surface until \n",
        "it's smooth and elastic. Place the dough in a bowl and cover it with a damp cloth. Let it rise in a warm place for \n",
        "several hours or until it has doubled in size.\\n\\nAfter it has risen, gently shape the dough into a round or oblong \n",
        "shape. Place it in a proofing basket or a greased bread pan and cover it with a damp cloth. Let it rise for another \n",
        "few hours or until it has doubled in size again.\\n\\nPreheat your oven to 425Â°F and place a baking dish with water \n",
        "in the oven. This will create steam, which will help the bread rise and develop a crispy crust. Score the top of \n",
        "the bread with a sharp knife or razor blade.\\n\\nBake the bread in the oven for 40-45 minutes or until the crust \n",
        "is golden brown. Remove from the oven and let it cool completely before slicing. Sourdough bread has a tangy \n",
        "flavor and chewy texture that's perfect for sandwiches or toast.\n",
        "\"\"\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "id": "daec1008-6289-4783-884e-1f8aea068600",
      "metadata": {
        "gather": {
          "logged": 1689181139444
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Customer: \n",
            "Generate a short summary of the recipe below, delimited by three\n",
            "backticks, in at most 50 words. \n",
            "\n",
            "Recipe: ```\n",
            "Making sourdough bread is a bit different from making regular bread because it requires a sourdough starter. \n",
            "To make the starter, you'll need flour and water. Mix equal parts of flour and water in a jar and leave it on your \n",
            "counter. After a few days, the mixture will start to bubble and ferment, which is when the sourdough starter is ready \n",
            "to use.\n",
            "\n",
            "Once you have the starter, you'll need to mix it with more flour and water to make the bread dough. \n",
            "In a mixing bowl, add the flour, salt, and a portion of the sourdough starter. Slowly mix in water until the dough \n",
            "comes together and is slightly sticky.\n",
            "\n",
            "Knead the dough for about 10 minutes on a floured surface until \n",
            "it's smooth and elastic. Place the dough in a bowl and cover it with a damp cloth. Let it rise in a warm place for \n",
            "several hours or until it has doubled in size.\n",
            "\n",
            "After it has risen, gently shape the dough into a round or oblong \n",
            "shape. Place it in a proofing basket or a greased bread pan and cover it with a damp cloth. Let it rise for another \n",
            "few hours or until it has doubled in size again.\n",
            "\n",
            "Preheat your oven to 425Â°F and place a baking dish with water \n",
            "in the oven. This will create steam, which will help the bread rise and develop a crispy crust. Score the top of \n",
            "the bread with a sharp knife or razor blade.\n",
            "\n",
            "Bake the bread in the oven for 40-45 minutes or until the crust \n",
            "is golden brown. Remove from the oven and let it cool completely before slicing. Sourdough bread has a tangy \n",
            "flavor and chewy texture that's perfect for sandwiches or toast.\n",
            "```\n",
            "\n",
            "\n",
            "Assistant Response: This recipe explains how to make sourdough bread using a sourdough starter made from flour and water. The dough is made by mixing the starter with flour, salt, and water, kneading it, and letting it rise. The bread is then baked in the oven with steam to create a crispy crust.\n",
            "\n",
            "Prompt tokens: 402\n",
            "Completion tokens: 63\n",
            "Total tokens: 465\n"
          ]
        }
      ],
      "source": [
        "prompt = f\"\"\"\n",
        "Generate a short summary of the recipe below, delimited by three\n",
        "backticks, in at most 50 words. \n",
        "\n",
        "Recipe: ```{recipe}```\n",
        "\"\"\"\n",
        "\n",
        "aoai_response, completion = aoai_completion(prompt)\n",
        "print(f\"Customer: {prompt}\")\n",
        "print(f\"\\nAssistant Response: {completion}\")\n",
        "print(f'\\nPrompt tokens: {aoai_response[\"usage\"][\"prompt_tokens\"]}')\n",
        "print(f'Completion tokens: {aoai_response[\"usage\"][\"completion_tokens\"]}')\n",
        "print(f'Total tokens: {aoai_response[\"usage\"][\"total_tokens\"]}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "id": "3f202bab-bc66-4559-96c0-b8e9026b406e",
      "metadata": {
        "gather": {
          "logged": 1689181145373
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "51  words\n",
            "277  characters\n"
          ]
        }
      ],
      "source": [
        "print(len(completion.split(\" \")), ' words')\n",
        "print(len(completion), ' characters')"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4b509848-dd1a-42ac-9175-423c2f3a8881",
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "Note, that the number of words/characters is known not to be exact with the GPT-35-Turbo model, but should be close."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "id": "3869851e-f6e7-4a3b-9d1a-7ccbb36ad192",
      "metadata": {
        "gather": {
          "logged": 1689181162763
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Assistant Response: The recipe explains how to make sourdough bread, which requires a sourdough starter made from equal parts flour and water left to ferment. The starter is then mixed with flour, salt, and water to make the bread dough, which is kneaded and left to rise. The dough is shaped and left to rise again before being baked in the oven with steam to create a crispy crust. Sourdough bread has a tangy flavor and chewy texture.\n",
            "\n",
            "Prompt tokens: 400\n",
            "Completion tokens: 93\n",
            "Total tokens: 493\n"
          ]
        }
      ],
      "source": [
        "prompt = f\"\"\"\n",
        "Summarize the recipe below, delimited by three backticks, but focus on the sourdough instructions.\n",
        "\n",
        "Recipe: ```{recipe}```\n",
        "\"\"\"\n",
        "\n",
        "aoai_response, completion = aoai_completion(prompt)\n",
        "#print(f\"Customer: {prompt}\")\n",
        "print(f\"\\nAssistant Response: {completion}\")\n",
        "print(f'\\nPrompt tokens: {aoai_response[\"usage\"][\"prompt_tokens\"]}')\n",
        "print(f'Completion tokens: {aoai_response[\"usage\"][\"completion_tokens\"]}')\n",
        "print(f'Total tokens: {aoai_response[\"usage\"][\"total_tokens\"]}')"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e3a12ced-f529-4f6a-8c58-54f4d7f3937c",
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "### Extractive Summarization \n",
        "\n",
        "Extrative summarization selects parts of the original text to form a summary."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "id": "a138320e-eeab-40ea-b32e-170174de0661",
      "metadata": {
        "gather": {
          "logged": 1689181170376
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Assistant Response: To make the starter, you'll need flour and water. Mix equal parts of flour and water in a jar and leave it on your \n",
            "counter. After a few days, the mixture will start to bubble and ferment, which is when the sourdough starter is ready \n",
            "to use.\n",
            "\n",
            "Once you have the starter, you'll need to mix it with more flour and water to make the bread dough. \n",
            "\n",
            "Sourdough bread has a tangy flavor and chewy texture that's perfect for sandwiches or toast.\n",
            "\n",
            "Prompt tokens: 401\n",
            "Completion tokens: 103\n",
            "Total tokens: 504\n"
          ]
        }
      ],
      "source": [
        "prompt = f\"\"\"\n",
        "Extract only the sentences relevant to the sourdough information from the recipe below, delimited by three backticks. \n",
        "\n",
        "Recipe: ```{recipe}```\n",
        "\"\"\"\n",
        "\n",
        "aoai_response, completion = aoai_completion(prompt)\n",
        "#print(f\"Customer: {prompt}\")\n",
        "print(f\"\\nAssistant Response: {completion}\")\n",
        "print(f'\\nPrompt tokens: {aoai_response[\"usage\"][\"prompt_tokens\"]}')\n",
        "print(f'Completion tokens: {aoai_response[\"usage\"][\"completion_tokens\"]}')\n",
        "print(f'Total tokens: {aoai_response[\"usage\"][\"total_tokens\"]}')"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "57cd9b38-8066-46fe-8c1c-2ccd8640c715",
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "### Summarize Multiple Recipes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "id": "1b96831a-52f2-40c3-921a-c04e4d486e55",
      "metadata": {
        "gather": {
          "logged": 1689181182541
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [],
      "source": [
        "recipe2 =\"\"\"\n",
        "    Ingredients:\n",
        "\n",
        "    1 3/4 cups all-purpose flour\n",
        "    2 cups granulated sugar\n",
        "    3/4 cup unsweetened cocoa powder\n",
        "    2 tsp baking soda\n",
        "    1 tsp baking powder\n",
        "    1 tsp salt\n",
        "    1 cup buttermilk\n",
        "    1/2 cup vegetable oil\n",
        "    2 large eggs\n",
        "    2 tsp vanilla extract\n",
        "    1 cup boiling water\n",
        "\n",
        "    Instructions:\n",
        "    Preheat your oven to 350Â°F. Grease two 9-inch round cake pans with butter or cooking spray and line the bottom with parchment paper.\n",
        "    In a large mixing bowl, whisk together the flour, sugar, cocoa powder, baking soda, baking powder, and salt until well combined.\n",
        "    In a separate bowl, whisk together the buttermilk, vegetable oil, eggs, and vanilla extract until smooth.\n",
        "    Add the wet ingredients to the dry ingredients and mix until well combined.\n",
        "    Slowly pour in the boiling water and mix until the batter is smooth.\n",
        "    Pour the batter evenly into the prepared cake pans.\n",
        "    Bake for 30-35 minutes or until a toothpick inserted into the center of the cakes comes out clean.\n",
        "    Let the cakes cool in the pans for 10 minutes before removing them and placing them on a wire rack to cool completely.\n",
        "    Once the cakes are cool, you can frost them with your favorite frosting or serve them as is.\n",
        "\n",
        "    Enjoy your delicious homemade chocolate cake!\n",
        "\n",
        "\"\"\"\n",
        "\n",
        "recipe3 =\"\"\"\n",
        "    Ingredients:\n",
        "\n",
        "    1 standing rib roast (4-5 pounds)\n",
        "    2 tbsp olive oil\n",
        "    2 tbsp kosher salt\n",
        "    1 tbsp black pepper\n",
        "    1 tbsp garlic powder\n",
        "    1 tbsp dried thyme\n",
        "    1 tbsp dried rosemary\n",
        "\n",
        "    Instructions:\n",
        "    Preheat your oven to 450Â°F.\n",
        "    Rub the olive oil all over the standing rib roast.\n",
        "    In a small mixing bowl, combine the kosher salt, black pepper, garlic powder, dried thyme, and dried rosemary. Mix well.\n",
        "    Sprinkle the spice mixture all over the standing rib roast, making sure to coat it evenly.\n",
        "    Place the standing rib roast on a roasting pan with the bone side down.\n",
        "    Roast in the oven for 15 minutes.\n",
        "    Reduce the oven temperature to 325Â°F and continue roasting for 1-2 hours or until the internal temperature reaches 135Â°F for medium-rare or 145Â°F for medium.\n",
        "    Remove the standing rib roast from the oven and let it rest for 10-15 minutes before slicing and serving.\n",
        "\n",
        "    Enjoy your delicious and flavorful standing rib roast!\n",
        "\"\"\"\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "id": "75d381a4-83eb-4b96-b891-50cb2a854bb7",
      "metadata": {
        "gather": {
          "logged": 1689181188759
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0 This recipe explains how to make sourdough bread using a sourdough starter, flour, water, and salt. The dough is kneaded, left to rise, shaped, and baked in the oven with steam to create a crispy crust. \n",
            "\n",
            "1 A classic chocolate cake recipe made with flour, sugar, cocoa powder, buttermilk, eggs, and vegetable oil, topped with frosting. \n",
            "\n",
            "2 A flavorful standing rib roast recipe with olive oil, spices, and herbs, roasted in the oven for 1-2 hours. \n",
            "\n"
          ]
        }
      ],
      "source": [
        "recipes = [recipe, recipe2, recipe3]\n",
        "\n",
        "for i in range(len(recipes)):\n",
        "    prompt = f\"\"\"\n",
        "    Generate a short summary of the recipe below, delimited by three backticks in at most 20 words. \n",
        "\n",
        "    Recipe: ```{recipes[i]}```\n",
        "    \"\"\"\n",
        "\n",
        "    aoai_response, completion = aoai_completion(prompt)\n",
        "    print(i, completion, \"\\n\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a15e6173-9f77-4873-9787-b6b2750d05bf",
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "## Inferencing\n",
        "\n",
        "Inferencing is the process of using a model to make predictions on new data - in the context of the LLM, it refers to the ability to understand user input and generate appropriate responses.  Some ways this could be used is for understanding sentiment, extracting components of the text, and classification."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8da283b8-c0a8-45df-a3a4-415fb454c50e",
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "### Sentiment / Emotion"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "id": "66a23be7-c370-4a68-ad7d-c3f6a1150912",
      "metadata": {
        "gather": {
          "logged": 1689181369904
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [],
      "source": [
        "pos_review = \"\"\"\n",
        "    I organized a surprise birthday celebration at Joe's Restaurant and it was fantastic. The food \n",
        "    was delicious and beautifully presented, with a great selection of options for all tastes and \n",
        "    dietary restrictions. The staff were friendly and accommodating, making sure we had everything we \n",
        "    needed throughout the night. The atmosphere was cozy and intimate, perfect for a celebration with \n",
        "    friends and family. I highly recommend Joe's Restaurant for anyone looking for a great dining \n",
        "    experience. Thank you to the staff for making our celebration so memorable!\n",
        "\"\"\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "id": "1d90eb7d-d40e-4e36-b9ef-fb19ddf758ba",
      "metadata": {
        "gather": {
          "logged": 1689181370982
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [],
      "source": [
        "neg_review = \"\"\"\n",
        "    I was really disappointed with my experience at this restaurant. The service was slow and inattentive, \n",
        "    and the food was bland and overpriced. I ordered a steak that was supposed to be cooked medium-rare, \n",
        "    but it came out well-done and tough. When I brought it to the attention of the server, they didn't seem to care \n",
        "    and didn't offer to fix it or make it right. To top it off, the atmosphere was noisy and chaotic, \n",
        "    which made it difficult to have a conversation. Overall, I wouldn't recommend this restaurant and \n",
        "    won't be returning.\n",
        "\"\"\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "id": "5cec0632-0fe8-4983-911f-229762cf8559",
      "metadata": {
        "gather": {
          "logged": 1689181372286
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Assistant Response: positive\n",
            "\n",
            "Prompt tokens: 148\n",
            "Completion tokens: 1\n",
            "Total tokens: 149\n"
          ]
        }
      ],
      "source": [
        "prompt = f\"\"\"\n",
        "What is the sentiment of the following restaurant review? Give your answer as a single word, either \"positive\" or \"negative\".\n",
        "\n",
        "Review text: '''{pos_review}'''\n",
        "\"\"\"\n",
        "aoai_response, completion = aoai_completion(prompt)\n",
        "#print(f\"Customer: {prompt}\")\n",
        "print(f\"\\nAssistant Response: {completion}\")\n",
        "print(f'\\nPrompt tokens: {aoai_response[\"usage\"][\"prompt_tokens\"]}')\n",
        "print(f'Completion tokens: {aoai_response[\"usage\"][\"completion_tokens\"]}')\n",
        "print(f'Total tokens: {aoai_response[\"usage\"][\"total_tokens\"]}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "id": "6322bd27-24fe-4860-bef8-d75be76c0559",
      "metadata": {
        "gather": {
          "logged": 1689181373744
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Assistant Response: negative\n",
            "\n",
            "Prompt tokens: 169\n",
            "Completion tokens: 1\n",
            "Total tokens: 170\n"
          ]
        }
      ],
      "source": [
        "prompt = f\"\"\"\n",
        "What is the sentiment of the following restaurant review? Give your answer as a single word, either \"positive\" or \"negative\".\n",
        "\n",
        "Review text: '''{neg_review}'''\n",
        "\"\"\"\n",
        "\n",
        "aoai_response, completion = aoai_completion(prompt)\n",
        "#print(f\"Customer: {prompt}\")\n",
        "print(f\"\\nAssistant Response: {completion}\")\n",
        "print(f'\\nPrompt tokens: {aoai_response[\"usage\"][\"prompt_tokens\"]}')\n",
        "print(f'Completion tokens: {aoai_response[\"usage\"][\"completion_tokens\"]}')\n",
        "print(f'Total tokens: {aoai_response[\"usage\"][\"total_tokens\"]}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 60,
      "id": "f86dd539-0c20-4cb6-8d85-ac8a50455202",
      "metadata": {
        "gather": {
          "logged": 1689112179217
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Assistant Response: happy, satisfied, grateful\n",
            "\n",
            "Prompt tokens: 158\n",
            "Completion tokens: 5\n",
            "Total tokens: 163\n"
          ]
        }
      ],
      "source": [
        "prompt = f\"\"\"\n",
        "List 3 emotions that the writer of the restaurant review is expressing. \n",
        "The review is delimited by three backticks. \n",
        "Format the list as lower-case words separated by commas.\n",
        "\n",
        "Review text: '''{pos_review}'''\n",
        "\"\"\"\n",
        "\n",
        "aoai_response, completion = aoai_completion(prompt)\n",
        "#print(f\"Customer: {prompt}\")\n",
        "print(f\"\\nAssistant Response: {completion}\")\n",
        "print(f'\\nPrompt tokens: {aoai_response[\"usage\"][\"prompt_tokens\"]}')\n",
        "print(f'Completion tokens: {aoai_response[\"usage\"][\"completion_tokens\"]}')\n",
        "print(f'Total tokens: {aoai_response[\"usage\"][\"total_tokens\"]}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "id": "d42b1bb0-f54f-4b49-a326-fac993419685",
      "metadata": {
        "gather": {
          "logged": 1689187487210
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Assistant Response: angry\n",
            "\n",
            "Prompt tokens: 173\n",
            "Completion tokens: 2\n",
            "Total tokens: 175\n"
          ]
        }
      ],
      "source": [
        "prompt = f\"\"\"\n",
        "Is the writer of the following review expressing anger?\n",
        "The review is delimited by three backticks. \n",
        "Give your answer as either angry or not angry.\n",
        "\n",
        "Review text: '''{neg_review}'''\n",
        "\"\"\"\n",
        "aoai_response, completion = aoai_completion(prompt)\n",
        "#print(f\"Customer: {prompt}\")\n",
        "print(f\"\\nAssistant Response: {completion}\")\n",
        "print(f'\\nPrompt tokens: {aoai_response[\"usage\"][\"prompt_tokens\"]}')\n",
        "print(f'Completion tokens: {aoai_response[\"usage\"][\"completion_tokens\"]}')\n",
        "print(f'Total tokens: {aoai_response[\"usage\"][\"total_tokens\"]}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "id": "a9eabc67-1832-47b6-b80d-a63d4e2f3b2d",
      "metadata": {
        "gather": {
          "logged": 1689187488530
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Assistant Response: not angry\n",
            "\n",
            "Prompt tokens: 152\n",
            "Completion tokens: 2\n",
            "Total tokens: 154\n"
          ]
        }
      ],
      "source": [
        "prompt = f\"\"\"\n",
        "Is the writer of the following review expressing anger?\n",
        "The review is delimited with triple backticks. \n",
        "Give your answer as either angry or not angry.\n",
        "\n",
        "Review text: '''{pos_review}'''\n",
        "\"\"\"\n",
        "aoai_response, completion = aoai_completion(prompt)\n",
        "#print(f\"Customer: {prompt}\")\n",
        "print(f\"\\nAssistant Response: {completion}\")\n",
        "print(f'\\nPrompt tokens: {aoai_response[\"usage\"][\"prompt_tokens\"]}')\n",
        "print(f'Completion tokens: {aoai_response[\"usage\"][\"completion_tokens\"]}')\n",
        "print(f'Total tokens: {aoai_response[\"usage\"][\"total_tokens\"]}')"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "86df0b7f-8758-41dd-8398-8769852ea591",
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "### Topic Extraction"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "id": "855d9ed0-62a9-44ad-8368-5a01b8bbf5c7",
      "metadata": {
        "gather": {
          "logged": 1689187491125
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Assistant Response: Surprise birthday celebration, Joe's Restaurant, Food, Staff, Dining experience.\n",
            "\n",
            "Prompt tokens: 167\n",
            "Completion tokens: 16\n",
            "Total tokens: 183\n"
          ]
        }
      ],
      "source": [
        "prompt = f\"\"\"\n",
        "Determine five topics that are being discussed in the \n",
        "following text sample, which is delimited by three backticks.\n",
        "\n",
        "Make each item one or two words long. \n",
        "\n",
        "Format your response as a list of items separated by commas.\n",
        "\n",
        "Text sample: '''{pos_review}'''\n",
        "\"\"\"\n",
        "aoai_response, completion = aoai_completion(prompt)\n",
        "#print(f\"Customer: {prompt}\")\n",
        "print(f\"\\nAssistant Response: {completion}\")\n",
        "print(f'\\nPrompt tokens: {aoai_response[\"usage\"][\"prompt_tokens\"]}')\n",
        "print(f'Completion tokens: {aoai_response[\"usage\"][\"completion_tokens\"]}')\n",
        "print(f'Total tokens: {aoai_response[\"usage\"][\"total_tokens\"]}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "id": "77d95552-6c1f-4a8f-b56c-ca2b90e73653",
      "metadata": {
        "gather": {
          "logged": 1689187528024
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Assistant Response: - Topic: Name of the restaurant\n",
            "- Extracted: Joe's Restaurant\n",
            "\n",
            "- Topic: Favorite part of experience\n",
            "- Extracted: The food was delicious and beautifully presented, with a great selection of options for all tastes and dietary restrictions.\n",
            "\n",
            "- Topic: Sentiment of the Reviewer\n",
            "- Extracted: Positive\n",
            "\n",
            "Prompt tokens: 214\n",
            "Completion tokens: 64\n",
            "Total tokens: 278\n"
          ]
        }
      ],
      "source": [
        "prompt = f\"\"\"\n",
        "Identify the following items from the review text: \n",
        "- Name of the restaurant\n",
        "- Favorite part of experience\n",
        "- Sentiment (positive or negative) of the Reviewer\n",
        "\n",
        "The review is delimited with triple backticks. \n",
        "Format your response as a list including  \n",
        "\"Topic\" and \"Extracted\" as the key. \n",
        "If the information isn't present, use \"unknown\" as the value. \n",
        "Make your response as short as possible.\n",
        "  \n",
        "Review text: '''{pos_review}'''\n",
        "\"\"\"\n",
        "aoai_response, completion = aoai_completion(prompt)\n",
        "#print(f\"Customer: {prompt}\")\n",
        "print(f\"\\nAssistant Response: {completion}\")\n",
        "print(f'\\nPrompt tokens: {aoai_response[\"usage\"][\"prompt_tokens\"]}')\n",
        "print(f'Completion tokens: {aoai_response[\"usage\"][\"completion_tokens\"]}')\n",
        "print(f'Total tokens: {aoai_response[\"usage\"][\"total_tokens\"]}')"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "cf4cf928-c086-4c40-a46f-70c662b20a9f",
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "### Classification"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "id": "442dfe93-7cf5-4054-a00b-8852ba353e4d",
      "metadata": {
        "gather": {
          "logged": 1689187529791
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [],
      "source": [
        "news_headlines = \"\"\"\n",
        "\"Record Heatwave Sweeps Across the West\"\n",
        "\"New Study Shows Benefits of Plant-Based Diets\"\n",
        "\"AI-Powered Drone Revolutionizes Agriculture Industry\"\n",
        "\"LeBron James Signs Four-Year Deal with Lakers\"\n",
        "\"NASA Launches Mission to Explore Europa's Ocean\"\n",
        "\"\"\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "id": "12800683-1d95-4012-8012-49ed416a0587",
      "metadata": {
        "gather": {
          "logged": 1689187531270
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Assistant Response: weather, food, technology, sports, technology\n",
            "\n",
            "Prompt tokens: 113\n",
            "Completion tokens: 9\n",
            "Total tokens: 122\n"
          ]
        }
      ],
      "source": [
        "prompt = f\"\"\"\n",
        "Classify the following news headlines into 1 of the following categories: sports, news, food, technology, weather\n",
        "\n",
        "Make each item one or two words long. \n",
        "\n",
        "Format your response as a list of items separated by commas.\n",
        "\n",
        "Text sample: '''{news_headlines}'''\n",
        "\"\"\"\n",
        "aoai_response, completion = aoai_completion(prompt)\n",
        "#print(f\"Customer: {prompt}\")\n",
        "print(f\"\\nAssistant Response: {completion}\")\n",
        "print(f'\\nPrompt tokens: {aoai_response[\"usage\"][\"prompt_tokens\"]}')\n",
        "print(f'Completion tokens: {aoai_response[\"usage\"][\"completion_tokens\"]}')\n",
        "print(f'Total tokens: {aoai_response[\"usage\"][\"total_tokens\"]}')"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2092d805-690e-4ce4-a141-2c923f06d7d5",
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "## Chatting / Advanced Conversations\n",
        "\n",
        "In the previous steps using the \"get_completion\" function, the message was constructed using a default pattern supplying just the prompt:\n",
        "\n",
        "```\n",
        "messages = [{\"role\": \"user\", \"content\": prompt}]\n",
        "```\n",
        "\n",
        "The same API call/SDK method is used for conversations, we add more context and information to each call by expanding the roles used to help manage the conversation and ensure that the AI model responds appropriately to requests and stays within its intended scope and does not provide inappropriate or irrelevant responses.\n",
        "\n",
        "The **system** role handles the interactions between the user and the assistant.  You can provide details about what is expected during their expectations by using the \"system\" role.\n",
        "\n",
        "The **user** initiates the conversation.\n",
        "\n",
        "The **assistant** is the AI model responding to user requests and messages.\n",
        "\n",
        "The format for adding the additional information is:\n",
        "\n",
        "```\n",
        "messages = [\n",
        "\t{\"role\": \"system\", \"content\": \"<instructions or description of the environment>\"},\n",
        "\t{\"role\": \"user\", \"content\": \"<user request>\" },\n",
        "\t{\"role\": \"assistant\", \"content\": \"<response to the user request>\" }\n",
        "]\n",
        "```\n",
        "\n",
        "Using these additional roles allow for you to provide details of how the assistant should respond, and to provide one/few-shot examples for the conversation."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "id": "48728298-98ab-4051-a613-316d86479f3a",
      "metadata": {
        "gather": {
          "logged": 1689187533564
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [],
      "source": [
        "messages =  [  \n",
        "{'role':'system', 'content': 'You are an assistant that speaks like a Pirate.'},    \n",
        "{'role':'user', 'content': 'Tell me a joke'},   \n",
        "{'role':'assistant', 'content': 'Why did the tomato turn red?'},   \n",
        "{'role':'user', 'content':'I don\\'t know.'}  ]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "id": "1bd3553f",
      "metadata": {
        "gather": {
          "logged": 1689187536608
        }
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Customer: [{'role': 'system', 'content': 'You are an assistant that speaks like a Pirate.'}, {'role': 'user', 'content': 'Tell me a joke'}, {'role': 'assistant', 'content': 'Why did the tomato turn red?'}, {'role': 'user', 'content': \"I don't know.\"}]\n",
            "\n",
            "Assistant Response: Because it saw the salad dressing! Ahoy!\n",
            "\n",
            "Prompt tokens: 49\n",
            "Completion tokens: 10\n",
            "Total tokens: 59\n"
          ]
        }
      ],
      "source": [
        "aoai_response, completion = aoai_completion(user_request = None, messages = messages)\n",
        "print(f\"Customer: {messages}\")\n",
        "print(f\"\\nAssistant Response: {completion}\")\n",
        "print(f'\\nPrompt tokens: {aoai_response[\"usage\"][\"prompt_tokens\"]}')\n",
        "print(f'Completion tokens: {aoai_response[\"usage\"][\"completion_tokens\"]}')\n",
        "print(f'Total tokens: {aoai_response[\"usage\"][\"total_tokens\"]}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6651265e-ffb9-4cb5-934e-2bfe7b45e3c9",
      "metadata": {
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernel_info": {
      "name": "python38-azureml"
    },
    "kernelspec": {
      "display_name": "Python 3.8 - AzureML",
      "language": "python",
      "name": "python38-azureml"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.5"
    },
    "microsoft": {
      "host": {
        "AzureML": {
          "notebookHasBeenCompleted": true
        }
      },
      "ms_spell_check": {
        "ms_spell_check_language": "en"
      }
    },
    "nteract": {
      "version": "nteract-front-end@1.0.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
